{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp-classification-smote-optuna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjgHRcThNT3YMY4JUj6sqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phraretein/flight_delay_prediction/blob/master/mlp_classification_smote_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0qf34cE2TE6"
      },
      "source": [
        "# ANN - MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J3ABrSJy6jE",
        "outputId": "bf40405f-c629-4248-9d31-527f6e14560b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvUdPZPNzDw_",
        "outputId": "48ae6243-97e7-4fd8-92c5-8f9a8940b7a8"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 10.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219244 sha256=66f97807504f2fad90e2e4e7fb92359c56513ec219e375e5681fa26234933cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB94ccVNzlvj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle5 as pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgDrUoRyzodd"
      },
      "source": [
        "# Retrieve data\n",
        "df = pickle.load(open(r'/content/drive/My Drive/Senior Project/df_train_update.pkl', \"rb\"))\n",
        "df_test = pickle.load(open(r'/content/drive/My Drive/Senior Project/df_test_update.pkl', \"rb\"))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECkAdKTzqGo"
      },
      "source": [
        "# One-hot encoding\n",
        "encode_columns = ['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST']\n",
        "df_encoded = pd.get_dummies(df, columns=encode_columns)\n",
        "df_test_encoded = pd.get_dummies(df_test, columns=encode_columns)\n",
        "# df_encoded.info(memory_usage='deep')\n",
        "del df, df_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS69-3rVztDh"
      },
      "source": [
        "# y and X\n",
        "y = df_encoded[['DEP_DELAY_GROUP']].copy()\n",
        "X = df_encoded.drop(['DEP_DELAY_GROUP'], axis=1).copy()\n",
        "y_test = df_test_encoded[['DEP_DELAY_GROUP']].copy()\n",
        "X_test = df_test_encoded.drop(['DEP_DELAY_GROUP'], axis=1).copy()\n",
        "del df_encoded\n",
        "del df_test_encoded"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw0jC4Jyzu0a"
      },
      "source": [
        "# Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_scaled = X.copy()\n",
        "scale_column = ['YEAR', 'MONTH', 'DAY_OF_MONTH', 'CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'DISTANCE']\n",
        "features = X_scaled[scale_column]\n",
        "scaler = MinMaxScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "X_scaled[scale_column] = features\n",
        "\n",
        "X_test_scaled = X_test.copy()\n",
        "test_features = X_test_scaled[scale_column]\n",
        "test_scaler = MinMaxScaler().fit(test_features.values)\n",
        "test_features = test_scaler.transform(test_features.values)\n",
        "X_test_scaled[scale_column] = test_features\n",
        "del features\n",
        "del scaler"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivzuuGZzzwj"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRjLPQvPhyGI",
        "outputId": "b8dac4f1-4b89-4b91-dead-1af55e9d10d4"
      },
      "source": [
        "# Oversample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogxHOFBH0Xf1"
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaYEHXKA0bs9"
      },
      "source": [
        "# One-hot encoded y\n",
        "y_train_df_encoded = pd.get_dummies(y_resampled, columns=['DEP_DELAY_GROUP'])\n",
        "y_train_encoded = y_train_df_encoded.to_numpy()\n",
        "del y_train_df_encoded \n",
        "\n",
        "y_test_df_encoded = pd.get_dummies(y_test, columns=['DEP_DELAY_GROUP'])\n",
        "y_test_encoded = y_test_df_encoded.to_numpy()\n",
        "del y_test_df_encoded "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF7WsRjY0y64"
      },
      "source": [
        "# Calculate class weight\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_integers = np.argmax(y_train_encoded, axis=1)\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
        "d_class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yd-VQCs03zy"
      },
      "source": [
        "def baseline_model(X):\n",
        "    # alpha = 10\n",
        "    # n_h = X.shape[0] / (alpha * (37 + 3))\n",
        "    # n_h = int((2 * 37) + 1)\n",
        "    # n_h = int(((2/3) * 37) + 3)\n",
        "    # Create model here\n",
        "    model = Sequential()\n",
        "    model.add(Dense(37, input_dim = X.shape[1], activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "    model.add(Dense(64, activation = 'relu', name='hidden_1'))\n",
        "    model.add(Dense(16, activation = 'relu', name='hidden_2'))\n",
        "    model.add(Dense(8, activation = 'relu', name='hidden_3'))\n",
        "    # model.add(Dense(99, activation = 'relu', name='hidden_3'))\n",
        "    model.add(Dense(3, activation = 'softmax', name='output_layer')) # Softmax for multi-class classification\n",
        "    # Compile model here\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsfm0AsbBCB2"
      },
      "source": [
        "baseline_model = baseline_model(X_scaled)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWEOfCSE1W-s",
        "outputId": "346f9310-98ec-42b9-ff29-1ec241fb0c94"
      },
      "source": [
        "history = baseline_model.fit(X_resampled, \n",
        "                        y_train_encoded, \n",
        "                        batch_size=128, \n",
        "                        epochs=20, \n",
        "                        verbose=1, \n",
        "                        # class_weight = d_class_weights, \n",
        "                        validation_data=(X_test_scaled, y_test_encoded))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.9051 - accuracy: 0.5632 - val_loss: 0.9721 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.9034 - accuracy: 0.5645 - val_loss: 0.9962 - val_accuracy: 0.4947\n",
            "Epoch 3/20\n",
            "10227/10227 [==============================] - 38s 4ms/step - loss: 0.9027 - accuracy: 0.5647 - val_loss: 0.9748 - val_accuracy: 0.5081\n",
            "Epoch 4/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.9019 - accuracy: 0.5651 - val_loss: 0.9610 - val_accuracy: 0.5146\n",
            "Epoch 5/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.9013 - accuracy: 0.5652 - val_loss: 0.9728 - val_accuracy: 0.5041\n",
            "Epoch 6/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.9003 - accuracy: 0.5657 - val_loss: 0.9928 - val_accuracy: 0.4893\n",
            "Epoch 7/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8998 - accuracy: 0.5660 - val_loss: 0.9809 - val_accuracy: 0.4987\n",
            "Epoch 8/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8992 - accuracy: 0.5662 - val_loss: 0.9751 - val_accuracy: 0.5057\n",
            "Epoch 9/20\n",
            "10227/10227 [==============================] - 38s 4ms/step - loss: 0.8984 - accuracy: 0.5665 - val_loss: 0.9366 - val_accuracy: 0.5312\n",
            "Epoch 10/20\n",
            "10227/10227 [==============================] - 38s 4ms/step - loss: 0.8981 - accuracy: 0.5667 - val_loss: 1.0149 - val_accuracy: 0.4877\n",
            "Epoch 11/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8973 - accuracy: 0.5675 - val_loss: 0.9710 - val_accuracy: 0.5046\n",
            "Epoch 12/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8970 - accuracy: 0.5675 - val_loss: 1.0279 - val_accuracy: 0.4705\n",
            "Epoch 13/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8963 - accuracy: 0.5679 - val_loss: 0.9728 - val_accuracy: 0.5116\n",
            "Epoch 14/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8959 - accuracy: 0.5679 - val_loss: 0.9548 - val_accuracy: 0.5155\n",
            "Epoch 15/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8954 - accuracy: 0.5683 - val_loss: 0.9706 - val_accuracy: 0.5033\n",
            "Epoch 16/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8948 - accuracy: 0.5688 - val_loss: 1.0110 - val_accuracy: 0.4769\n",
            "Epoch 17/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8947 - accuracy: 0.5686 - val_loss: 0.9767 - val_accuracy: 0.5048\n",
            "Epoch 18/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8941 - accuracy: 0.5690 - val_loss: 0.9906 - val_accuracy: 0.4982\n",
            "Epoch 19/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8939 - accuracy: 0.5689 - val_loss: 0.9796 - val_accuracy: 0.5073\n",
            "Epoch 20/20\n",
            "10227/10227 [==============================] - 37s 4ms/step - loss: 0.8935 - accuracy: 0.5694 - val_loss: 0.9790 - val_accuracy: 0.5075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_HS5FDImDQc"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biN_IJkpmEJM",
        "outputId": "f44bf109-3d97-472f-cacb-402f9aae6cad"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "O4NIdIqIl9rO",
        "outputId": "7d6d5a1c-8211-4ed2-fcd6-be0a66f6d836"
      },
      "source": [
        "# Plotting losses\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n",
        "\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dWuIa5ANmVWf",
        "outputId": "6cbb1549-9597-401a-9bd7-b4af5b784646"
      },
      "source": [
        "# Training and Validation Accuracy\n",
        "\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, acc_values, 'ro', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc_values, 'r-', label=\"Validation Accuracy\")\n",
        "\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi3fWGed9i22",
        "outputId": "7dc6ac49-5f2b-414f-fffb-9bc2e084c686"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = baseline_model.predict(X_test_scaled, batch_size=512, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1041/1041 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.53      0.66    430538\n",
            "         1.0       0.24      0.34      0.28     90587\n",
            "         2.0       0.03      0.38      0.06     11381\n",
            "\n",
            "    accuracy                           0.49    532506\n",
            "   macro avg       0.38      0.41      0.33    532506\n",
            "weighted avg       0.74      0.49      0.58    532506\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oD82NEjYD_h",
        "outputId": "7d4dd54b-8366-46f7-edd3-458790d0b364"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_bool)\n",
        "print(\"Accuracy using train sample: {:.4}%\".format(accuracy * 100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using train sample: 49.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjbboTkwaENk"
      },
      "source": [
        "# Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEzkfmONaGEN"
      },
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def focal_loss_model(X, y_train, y_pred):\n",
        "    alpha = 10\n",
        "    n_h = X.shape[0] / (alpha * (37 + 3))\n",
        "\n",
        "\n",
        "    def focal_loss(gamma=2.0, alpha=0.25):\n",
        "      gamma = float(gamma)\n",
        "      alpha = float(alpha)\n",
        "      def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "      return focal_loss_fixed\n",
        "\n",
        "\n",
        "    # Create model here\n",
        "    model = Sequential()\n",
        "    model.add(Dense(25, input_dim = X.shape[1], activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "    model.add(Dense(n_h, activation = 'relu', name='hidden_1'))\n",
        "    # model.add(Dense(198, activation = 'relu', name='hidden_2'))\n",
        "    # model.add(Dense(99, activation = 'relu', name='hidden_3'))\n",
        "    model.add(Dense(3, activation = 'softmax', name='output_layer')) # Softmax for multi-class classification\n",
        "    # Compile model here\n",
        "    model.compile(loss = focal_loss(alpha=1), optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X, y_train, epochs=80, batch_size=1028, verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXVwcZ6Mfz41"
      },
      "source": [
        "model_f = Sequential()\n",
        "model_f.add(Dense(25, input_dim = 37, activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "n_h = X.shape[0] / (8 * (37 + 3))\n",
        "model_f.add(Dense(n_h, activation = 'relu', name='hidden_1'))\n",
        "model_f.add(Dense(3, activation = 'softmax', name='output_layer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IjwMuVagLh-"
      },
      "source": [
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "  gamma = float(gamma)\n",
        "  alpha = float(alpha)\n",
        "  def focal_loss_fixed(y_true, y_pred):\n",
        "    epsilon = 1.e-9\n",
        "    y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "    y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "    model_out = tf.add(y_pred, epsilon)\n",
        "    ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "    weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "    fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "    reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "    return tf.reduce_mean(reduced_fl)\n",
        "  return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyzJ0BE9gPie"
      },
      "source": [
        "model_f.compile(loss=focal_loss(alpha=1), optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T2JIH0logiGT",
        "outputId": "50f6bc75-9676-4df5-abaf-c40699faecd7"
      },
      "source": [
        "model_f.fit(X_scaled, y_train_encoded, epochs=3, batch_size=1028)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-900252ad64e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-37-d2daae72fb87>:6 focal_loss_fixed  *\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1405 convert_to_tensor_v2_with_dispatch\n        value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1415 convert_to_tensor_v2\n        as_ref=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1509 convert_to_tensor\n        (dtype.name, value.dtype.name, value))\n\n    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype uint8: <tf.Tensor 'IteratorGetNext:1' shape=(None, 3) dtype=uint8>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "blMRpKB1cyCQ",
        "outputId": "108fe187-9088-409e-be0a-9c77f1e7e052"
      },
      "source": [
        "focal_loss_model = focal_loss_model(X_scaled, y_train_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-884a1c289c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfocal_loss_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfocal_loss_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: focal_loss_model() missing 1 required positional argument: 'y_pred'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "xQZV716OdAW-",
        "outputId": "b7fd7e22-bf2d-4e9d-ab83-df5befce234a"
      },
      "source": [
        "focal_history = focal_loss_model.fit(X_scaled, \n",
        "                        y_train_encoded, \n",
        "                        batch_size=1028, \n",
        "                        epochs=80, \n",
        "                        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b381fc237030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-23-f4227a847ddd>:16 focal_loss_fixed  *\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1405 convert_to_tensor_v2_with_dispatch\n        value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1415 convert_to_tensor_v2\n        as_ref=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1509 convert_to_tensor\n        (dtype.name, value.dtype.name, value))\n\n    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype uint8: <tf.Tensor 'IteratorGetNext:1' shape=(None, 3) dtype=uint8>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfhrM8gVmogJ"
      },
      "source": [
        "# Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm9WYZSur3qX",
        "outputId": "60c89ae8-a613-4b52-a825-64e6d3b08b69"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 24.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 25.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 51kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 61kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 71kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 102kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 112kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 122kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 133kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 143kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 153kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 163kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 174kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 194kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 204kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 215kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 225kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 235kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 245kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 256kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 266kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 276kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 286kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/a4/97eb6273839655cac14947986fa7a5935350fcfd4fff872e9654264c82d8/alembic-1.5.8-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 29.9MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 28.4MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (3.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=e12970108620d013d45f8e0a20b70e07dd0f987c0b6da5fa9a19ebca7f8a8ae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, colorama, cmd2, pbr, stevedore, cliff, python-editor, Mako, alembic, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.5.8 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 optuna-2.7.0 pbr-5.5.1 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK2fkJSQlSvI"
      },
      "source": [
        "# Optuna\n",
        "import sklearn.metrics\n",
        "import optuna\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def opt(X_train, y_train, X_test, y_test, class_weights, trial):\n",
        "  # print(y_train)\n",
        "  # print(y_test)\n",
        "  # print(class_weights)\n",
        "  # print(X.shape[0])\n",
        "  # print(X.shape[1])\n",
        "  # print(y.shape[1])\n",
        "  # clear_session()\n",
        "  # One-hot encoded y\n",
        "  y_train_df_encoded = pd.get_dummies(y_train, columns=['DEP_DELAY_GROUP'])\n",
        "  y_train_encoded = y_train_df_encoded.to_numpy()\n",
        "  del y_train_df_encoded \n",
        "\n",
        "  y_test_df_encoded = pd.get_dummies(y_test, columns=['DEP_DELAY_GROUP'])\n",
        "  y_test_encoded = y_test_df_encoded.to_numpy()\n",
        "  del y_test_df_encoded \n",
        "  \n",
        "  # parameters\n",
        "  alpha = trial.suggest_discrete_uniform('alpha', 2, 10, 1)\n",
        "  input_layer = X.shape[1]\n",
        "  # n_h = int(X.shape[0] / (alpha * (input_layer + y.shape[1])))\n",
        "  n_h = trial.suggest_int('n_hidden_layer', 10, 20)\n",
        "  batch_val = [32, 64, 128, 256]\n",
        "  batch_size = batch_val[int(trial.suggest_discrete_uniform('batch_index', 0, 3, 1))]\n",
        "  # epochs_val = [100, 200]\n",
        "  # epochs = epochs_val[int(trial.suggest_discrete_uniform('epochs', 0, 1, 1))]\n",
        "  epochs = trial.suggest_int('epochs', 50, 100)\n",
        "  # print(batch_size)\n",
        "  # print(n_h)\n",
        "  # Create model \n",
        "  model = Sequential()\n",
        "  model.add(Dense(input_layer, input_dim = X.shape[1], activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "  model.add(Dense(n_h, activation = 'relu', name='hidden_1'))\n",
        "  model.add(Dense(3, activation = 'softmax', name='output_layer')) # Softmax for multi-class classification\n",
        "  # Compile model \n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, \n",
        "            y_train_encoded, \n",
        "            batch_size=batch_size, \n",
        "            epochs=epochs, \n",
        "            verbose=1, \n",
        "            class_weight=class_weights)\n",
        "  pred_test = model.predict(X_test)\n",
        "  y_pred_bool = np.argmax(pred_test, axis=1)\n",
        "\n",
        "  return (1.0 - accuracy_score(y_test, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LcnVwmCrR_8",
        "outputId": "fd49fd8c-74d2-4960-b95f-46acd8c155f9"
      },
      "source": [
        "import functools\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(functools.partial(opt, X_scaled, y, X_test_scaled, y_test, d_class_weights), n_trials=25, show_progress_bar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16287/16950 [===========================>..] - ETA: 1s - loss: 1.0071 - accuracy: 0.5196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-32ca3a6eb7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_class_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-042d1e4ea6e2>\u001b[0m in \u001b[0;36mopt\u001b[0;34m(X_train, y_train, X_test, y_test, class_weights, trial)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             class_weight=class_weights)\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0my_pred_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q86RFSy0jhZ",
        "outputId": "e5619d92-dcba-4446-9f63-0904b430a56c"
      },
      "source": [
        "# Best Param List\n",
        "print(study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 8.0, 'batch_index': 0.0, 'epochs': 80}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nb1_rbW7Ws8"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAW2T1C7_M21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72ec1fa-0913-4411-e086-78fc7d2e16e8"
      },
      "source": [
        "filename = r'/content/drive/My Drive/Senior Project/study.pkl'\n",
        "joblib.dump(study, open(filename, 'wb'))\n",
        "print(\"Study Saved Successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Study Saved Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBy1pRWJCEJu"
      },
      "source": [
        "## Load Optuna Study Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qYAZg_COO_"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSxpQ2oDB-HY"
      },
      "source": [
        "if os.path.exists(r'/content/drive/My Drive/Senior Project/study.pkl'):\n",
        "    study =  joblib.load(open(r'/content/drive/My Drive/Senior Project/study.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkZ0HuWJCVBO",
        "outputId": "e6c74948-bf3d-4715-9cce-bc52964c714a"
      },
      "source": [
        "print(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<optuna.study.Study object at 0x7f7331a53190>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "QR6nIW2KCW5j",
        "outputId": "c8751036-5d82-4e4e-ad5a-a3c7b86c461b"
      },
      "source": [
        "# Plot Parameter Importance Graph\n",
        "from optuna.visualization import plot_param_importances\n",
        "fig = plot_param_importances(study)\n",
        "fig.show()\n",
        "# fig.write_image(r'/content/drive/My Drive/Senior Project/Hyperparameter Importance.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"473d9115-8a78-4fec-a5f6-3e0efc6dc425\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"473d9115-8a78-4fec-a5f6-3e0efc6dc425\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '473d9115-8a78-4fec-a5f6-3e0efc6dc425',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"alpha (DiscreteUniformDistribution): 0.17088722513421042<extra></extra>\", \"batch_index (DiscreteUniformDistribution): 0.26050337890536407<extra></extra>\", \"epochs (IntUniformDistribution): 0.5686093959604256<extra></extra>\"], \"marker\": {\"color\": [\"rgb(8,48,107)\", \"rgb(8,48,107)\", \"rgb(8,81,156)\"]}, \"orientation\": \"h\", \"text\": [\"0.17088722513421042\", \"0.26050337890536407\", \"0.5686093959604256\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.17088722513421042, 0.26050337890536407, 0.5686093959604256], \"y\": [\"alpha\", \"batch_index\", \"epochs\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('473d9115-8a78-4fec-a5f6-3e0efc6dc425');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6Dr8fY-KCc5o",
        "outputId": "20469f38-5b08-4ffe-c681-eb2b9cc7fd35"
      },
      "source": [
        "# Plot Optimization History\n",
        "fig = optuna.visualization.plot_optimization_history(study)\n",
        "fig.show()\n",
        "# fig.write_image(r'/content/drive/My Drive/Senior Project/Optimization History Plot.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"96ac7b07-bd88-4e43-8149-fca04dac2c8a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"96ac7b07-bd88-4e43-8149-fca04dac2c8a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '96ac7b07-bd88-4e43-8149-fca04dac2c8a',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], \"y\": [0.4680435525609101, 0.5076581296736562, 0.4876621108494552, 0.4937747180313461, 0.5116167705152618, 0.49336908879899943, 0.4869053118650306, 0.5260090966111179, 0.508876895283809, 0.5081520208223006, 0.4991192587501362, 0.5109444776209094, 0.4781692600646753, 0.5226025622246511, 0.5025295489628285, 0.47874953521650465, 0.4365640950524501, 0.5639335519224197, 0.5098458984499705, 0.4865635316785163, 0.5112036296304643, 0.5009502240350343, 0.48855036375176997, 0.47311016213901813, 0.4276871997686411]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], \"y\": [0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4680435525609101, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4365640950524501, 0.4276871997686411]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('96ac7b07-bd88-4e43-8149-fca04dac2c8a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv85wnpEGnDW"
      },
      "source": [
        "def opt_model(X, alpha):\n",
        "  # parameters\n",
        "  alpha = alpha\n",
        "  input_layer = X.shape[1]\n",
        "  n_h = int(X.shape[0] / (alpha * (input_layer + y.shape[1])))\n",
        "  # batch_val = [32, 64, 128, 256]\n",
        "  # batch_size = batch_val[batch_index]\n",
        "  # epochs_val = [100, 200]\n",
        "  # epochs = epochs_val[int(trial.suggest_discrete_uniform('epochs', 0, 1, 1))]\n",
        "  # epochs = epochs\n",
        "  # print(batch_size)\n",
        "  # print(n_h)\n",
        "  # Create model \n",
        "  model = Sequential()\n",
        "  model.add(Dense(input_layer, input_dim = X.shape[1], activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "  model.add(Dense(n_h, activation = 'relu', name='hidden_1'))\n",
        "  model.add(Dense(3, activation = 'softmax', name='output_layer')) # Softmax for multi-class classification\n",
        "  # Compile model \n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "  # model.fit(X_train, \n",
        "  #           y_train_encoded, \n",
        "  #           batch_size=batch_size, \n",
        "  #           epochs=epochs, \n",
        "  #           verbose=1, \n",
        "  #           class_weight=class_weights)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p-mFQY7JJ9M"
      },
      "source": [
        "opt_alpha = study.best_params['alpha']\n",
        "opt_batch_index = int(study.best_params['batch_index'])\n",
        "opt_epochs = study.best_params['epochs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz_SYAYeKHnM",
        "outputId": "ba561827-d248-4097-bcb1-7eacd97ea3c9"
      },
      "source": [
        "opt_epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dPxtbEtI0dF"
      },
      "source": [
        "clf = opt_model(X_scaled, opt_alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw_sEVQCL02r"
      },
      "source": [
        "batch_val = [32, 64, 128, 256]\n",
        "opt_batch_size = batch_val[opt_batch_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwyzG-K_MAoC",
        "outputId": "4c3ba425-ec1c-4c65-9703-8bfa5c1e9064"
      },
      "source": [
        "history = clf.fit(X_scaled, \n",
        "                  y_train_encoded, \n",
        "                  batch_size=opt_batch_size, \n",
        "                  epochs=opt_epochs, \n",
        "                  verbose=1, \n",
        "                  class_weight = d_class_weights, \n",
        "                  validation_data=(X_test_scaled, y_test_encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0542 - accuracy: 0.4999 - val_loss: 1.0502 - val_accuracy: 0.4858\n",
            "Epoch 2/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0429 - accuracy: 0.5071 - val_loss: 1.0394 - val_accuracy: 0.5085\n",
            "Epoch 3/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0359 - accuracy: 0.5118 - val_loss: 1.0254 - val_accuracy: 0.5228\n",
            "Epoch 4/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0331 - accuracy: 0.5212 - val_loss: 1.0144 - val_accuracy: 0.5118\n",
            "Epoch 5/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0344 - accuracy: 0.5163 - val_loss: 1.0338 - val_accuracy: 0.5238\n",
            "Epoch 6/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0314 - accuracy: 0.5229 - val_loss: 1.0281 - val_accuracy: 0.5232\n",
            "Epoch 7/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0248 - accuracy: 0.5256 - val_loss: 1.0373 - val_accuracy: 0.5254\n",
            "Epoch 8/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0242 - accuracy: 0.5260 - val_loss: 1.0637 - val_accuracy: 0.4806\n",
            "Epoch 9/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0262 - accuracy: 0.5239 - val_loss: 1.0461 - val_accuracy: 0.4882\n",
            "Epoch 10/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0254 - accuracy: 0.5197 - val_loss: 1.0136 - val_accuracy: 0.5056\n",
            "Epoch 11/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0229 - accuracy: 0.5181 - val_loss: 1.0284 - val_accuracy: 0.5091\n",
            "Epoch 12/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0240 - accuracy: 0.5222 - val_loss: 1.0922 - val_accuracy: 0.4373\n",
            "Epoch 13/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0248 - accuracy: 0.5172 - val_loss: 0.9802 - val_accuracy: 0.5396\n",
            "Epoch 14/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0209 - accuracy: 0.5263 - val_loss: 1.0473 - val_accuracy: 0.4753\n",
            "Epoch 15/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0192 - accuracy: 0.5225 - val_loss: 1.0493 - val_accuracy: 0.4710\n",
            "Epoch 16/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0287 - accuracy: 0.5187 - val_loss: 0.9998 - val_accuracy: 0.5194\n",
            "Epoch 17/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0188 - accuracy: 0.5221 - val_loss: 1.0880 - val_accuracy: 0.4570\n",
            "Epoch 18/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0264 - accuracy: 0.5167 - val_loss: 1.0464 - val_accuracy: 0.4927\n",
            "Epoch 19/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0254 - accuracy: 0.5177 - val_loss: 1.0920 - val_accuracy: 0.4535\n",
            "Epoch 20/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0200 - accuracy: 0.5213 - val_loss: 1.0209 - val_accuracy: 0.5127\n",
            "Epoch 21/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0248 - accuracy: 0.5183 - val_loss: 0.9745 - val_accuracy: 0.5426\n",
            "Epoch 22/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0228 - accuracy: 0.5209 - val_loss: 1.0085 - val_accuracy: 0.5262\n",
            "Epoch 23/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0263 - accuracy: 0.5208 - val_loss: 1.0371 - val_accuracy: 0.4934\n",
            "Epoch 24/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0287 - accuracy: 0.5126 - val_loss: 1.0446 - val_accuracy: 0.4820\n",
            "Epoch 25/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0256 - accuracy: 0.5194 - val_loss: 1.0541 - val_accuracy: 0.4769\n",
            "Epoch 26/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0157 - accuracy: 0.5223 - val_loss: 1.0418 - val_accuracy: 0.4828\n",
            "Epoch 27/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0276 - accuracy: 0.5132 - val_loss: 1.1007 - val_accuracy: 0.4407\n",
            "Epoch 28/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0249 - accuracy: 0.5208 - val_loss: 1.0844 - val_accuracy: 0.4450\n",
            "Epoch 29/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0230 - accuracy: 0.5172 - val_loss: 1.0554 - val_accuracy: 0.4792\n",
            "Epoch 30/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0214 - accuracy: 0.5221 - val_loss: 1.0802 - val_accuracy: 0.4333\n",
            "Epoch 31/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0253 - accuracy: 0.5150 - val_loss: 1.1257 - val_accuracy: 0.4203\n",
            "Epoch 32/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0188 - accuracy: 0.5210 - val_loss: 1.0915 - val_accuracy: 0.4524\n",
            "Epoch 33/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0234 - accuracy: 0.5214 - val_loss: 1.1109 - val_accuracy: 0.4430\n",
            "Epoch 34/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0276 - accuracy: 0.5136 - val_loss: 0.9918 - val_accuracy: 0.5363\n",
            "Epoch 35/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0273 - accuracy: 0.5232 - val_loss: 1.1380 - val_accuracy: 0.4201\n",
            "Epoch 36/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0233 - accuracy: 0.5154 - val_loss: 1.0901 - val_accuracy: 0.4463\n",
            "Epoch 37/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0281 - accuracy: 0.5122 - val_loss: 1.0632 - val_accuracy: 0.4740\n",
            "Epoch 38/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0220 - accuracy: 0.5158 - val_loss: 1.0651 - val_accuracy: 0.4559\n",
            "Epoch 39/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0302 - accuracy: 0.5163 - val_loss: 1.0606 - val_accuracy: 0.4782\n",
            "Epoch 40/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0192 - accuracy: 0.5232 - val_loss: 1.1378 - val_accuracy: 0.4165\n",
            "Epoch 41/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0210 - accuracy: 0.5206 - val_loss: 1.0299 - val_accuracy: 0.5007\n",
            "Epoch 42/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0285 - accuracy: 0.5118 - val_loss: 1.0246 - val_accuracy: 0.5233\n",
            "Epoch 43/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0238 - accuracy: 0.5171 - val_loss: 1.0162 - val_accuracy: 0.5138\n",
            "Epoch 44/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0244 - accuracy: 0.5147 - val_loss: 0.9625 - val_accuracy: 0.5586\n",
            "Epoch 45/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0274 - accuracy: 0.5194 - val_loss: 1.0268 - val_accuracy: 0.5096\n",
            "Epoch 46/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0295 - accuracy: 0.5148 - val_loss: 1.0699 - val_accuracy: 0.4714\n",
            "Epoch 47/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0274 - accuracy: 0.5156 - val_loss: 1.0466 - val_accuracy: 0.4820\n",
            "Epoch 48/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0303 - accuracy: 0.5153 - val_loss: 1.0260 - val_accuracy: 0.5094\n",
            "Epoch 49/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0285 - accuracy: 0.5150 - val_loss: 0.9798 - val_accuracy: 0.5639\n",
            "Epoch 50/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0291 - accuracy: 0.5181 - val_loss: 1.1111 - val_accuracy: 0.4394\n",
            "Epoch 51/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0260 - accuracy: 0.5178 - val_loss: 1.0846 - val_accuracy: 0.4635\n",
            "Epoch 52/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0260 - accuracy: 0.5132 - val_loss: 1.0790 - val_accuracy: 0.4758\n",
            "Epoch 53/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0306 - accuracy: 0.5119 - val_loss: 1.0645 - val_accuracy: 0.4839\n",
            "Epoch 54/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0309 - accuracy: 0.5145 - val_loss: 1.1071 - val_accuracy: 0.4361\n",
            "Epoch 55/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0240 - accuracy: 0.5208 - val_loss: 1.0316 - val_accuracy: 0.4818\n",
            "Epoch 56/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0300 - accuracy: 0.5159 - val_loss: 1.0917 - val_accuracy: 0.4333\n",
            "Epoch 57/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0328 - accuracy: 0.5078 - val_loss: 1.0534 - val_accuracy: 0.4981\n",
            "Epoch 58/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0296 - accuracy: 0.5174 - val_loss: 1.0306 - val_accuracy: 0.5087\n",
            "Epoch 59/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0304 - accuracy: 0.5135 - val_loss: 1.0732 - val_accuracy: 0.4851\n",
            "Epoch 60/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0262 - accuracy: 0.5207 - val_loss: 1.0476 - val_accuracy: 0.5023\n",
            "Epoch 61/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0278 - accuracy: 0.5184 - val_loss: 1.0638 - val_accuracy: 0.4688\n",
            "Epoch 62/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0254 - accuracy: 0.5165 - val_loss: 1.0912 - val_accuracy: 0.4618\n",
            "Epoch 63/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0351 - accuracy: 0.5170 - val_loss: 1.1570 - val_accuracy: 0.3947\n",
            "Epoch 64/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0244 - accuracy: 0.5232 - val_loss: 1.0442 - val_accuracy: 0.5004\n",
            "Epoch 65/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0260 - accuracy: 0.5184 - val_loss: 1.1305 - val_accuracy: 0.4357\n",
            "Epoch 66/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0305 - accuracy: 0.5127 - val_loss: 1.1166 - val_accuracy: 0.4336\n",
            "Epoch 67/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0306 - accuracy: 0.5176 - val_loss: 1.1020 - val_accuracy: 0.4394\n",
            "Epoch 68/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0275 - accuracy: 0.5135 - val_loss: 1.0561 - val_accuracy: 0.4875\n",
            "Epoch 69/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0287 - accuracy: 0.5186 - val_loss: 1.0585 - val_accuracy: 0.4781\n",
            "Epoch 70/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0306 - accuracy: 0.5151 - val_loss: 1.0050 - val_accuracy: 0.5497\n",
            "Epoch 71/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0242 - accuracy: 0.5226 - val_loss: 1.0326 - val_accuracy: 0.5287\n",
            "Epoch 72/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0304 - accuracy: 0.5167 - val_loss: 1.1279 - val_accuracy: 0.4423\n",
            "Epoch 73/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0285 - accuracy: 0.5183 - val_loss: 1.0330 - val_accuracy: 0.5211\n",
            "Epoch 74/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0272 - accuracy: 0.5186 - val_loss: 1.0303 - val_accuracy: 0.5236\n",
            "Epoch 75/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0293 - accuracy: 0.5200 - val_loss: 1.0823 - val_accuracy: 0.4642\n",
            "Epoch 76/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0302 - accuracy: 0.5186 - val_loss: 1.0476 - val_accuracy: 0.4924\n",
            "Epoch 77/80\n",
            "16950/16950 [==============================] - 62s 4ms/step - loss: 1.0317 - accuracy: 0.5202 - val_loss: 1.0922 - val_accuracy: 0.4510\n",
            "Epoch 78/80\n",
            "16950/16950 [==============================] - 63s 4ms/step - loss: 1.0327 - accuracy: 0.5177 - val_loss: 1.1075 - val_accuracy: 0.4364\n",
            "Epoch 79/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0343 - accuracy: 0.5164 - val_loss: 1.0391 - val_accuracy: 0.5312\n",
            "Epoch 80/80\n",
            "16950/16950 [==============================] - 64s 4ms/step - loss: 1.0392 - accuracy: 0.5174 - val_loss: 1.1351 - val_accuracy: 0.4373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiHbX77flUU5",
        "outputId": "48add11b-4bdc-4870-8db9-e654a6994842"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_opt = clf.predict(X_test_scaled, batch_size=opt_batch_size, verbose=1)\n",
        "y_pred_opt_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_opt_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16641/16641 [==============================] - 15s 905us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.51      0.64    430538\n",
            "         1.0       0.23      0.35      0.28     90587\n",
            "         2.0       0.03      0.40      0.06     11381\n",
            "\n",
            "    accuracy                           0.48    532506\n",
            "   macro avg       0.38      0.42      0.33    532506\n",
            "weighted avg       0.74      0.48      0.56    532506\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Dajew1pmBK",
        "outputId": "79434bdc-3fd7-4fbf-b1f6-9a1a731997f3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_opt_bool)\n",
        "print(\"Accuracy using train sample: {:.4}%\".format(accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using train sample: 47.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uEfI8Bulk9g"
      },
      "source": [
        "def opt_model_new(X_train, y_train_encoded, alpha, batch_size, epochs, class_weights):\n",
        "  # parameters\n",
        "  alpha = alpha\n",
        "  input_layer = X.shape[1]\n",
        "  n_h = int(X.shape[0] / (alpha * (input_layer + y.shape[1])))\n",
        "  # batch_val = [32, 64, 128, 256]\n",
        "  # batch_size = batch_val[batch_index]\n",
        "  # epochs_val = [100, 200]\n",
        "  # epochs = epochs_val[int(trial.suggest_discrete_uniform('epochs', 0, 1, 1))]\n",
        "  # epochs = epochs\n",
        "  # print(batch_size)\n",
        "  # print(n_h)\n",
        "  # Create model \n",
        "  model = Sequential()\n",
        "  model.add(Dense(input_layer, input_dim = X.shape[1], activation = 'relu', name='input_layer')) # Rectified Linear Unit Activation Function\n",
        "  model.add(Dense(n_h, activation = 'relu', name='hidden_1'))\n",
        "  model.add(Dense(3, activation = 'softmax', name='output_layer')) # Softmax for multi-class classification\n",
        "  # Compile model \n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, \n",
        "            y_train_encoded, \n",
        "            batch_size=batch_size, \n",
        "            epochs=epochs, \n",
        "            verbose=1, \n",
        "            class_weight=class_weights)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JPJPRWMmxWf",
        "outputId": "4f57f154-b548-4a8c-ae8d-853a2ac8408a"
      },
      "source": [
        "clf_new = opt_model_new(X_scaled, y_train_encoded, alpha=opt_alpha, batch_size=opt_batch_size, epochs=opt_epochs, class_weights=d_class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0550 - accuracy: 0.4897\n",
            "Epoch 2/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0443 - accuracy: 0.5079\n",
            "Epoch 3/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0382 - accuracy: 0.5092\n",
            "Epoch 4/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0332 - accuracy: 0.5215\n",
            "Epoch 5/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0282 - accuracy: 0.5222\n",
            "Epoch 6/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0298 - accuracy: 0.5228\n",
            "Epoch 7/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0343 - accuracy: 0.5261\n",
            "Epoch 8/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0264 - accuracy: 0.5271\n",
            "Epoch 9/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0245 - accuracy: 0.5267\n",
            "Epoch 10/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0304 - accuracy: 0.5269\n",
            "Epoch 11/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0268 - accuracy: 0.5310\n",
            "Epoch 12/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0310 - accuracy: 0.5229\n",
            "Epoch 13/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0278 - accuracy: 0.5264\n",
            "Epoch 14/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0296 - accuracy: 0.5308\n",
            "Epoch 15/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0260 - accuracy: 0.5184\n",
            "Epoch 16/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0329 - accuracy: 0.5168\n",
            "Epoch 17/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0278 - accuracy: 0.5229\n",
            "Epoch 18/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0300 - accuracy: 0.5261\n",
            "Epoch 19/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0257 - accuracy: 0.5211\n",
            "Epoch 20/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0260 - accuracy: 0.5173\n",
            "Epoch 21/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0351 - accuracy: 0.5153\n",
            "Epoch 22/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0351 - accuracy: 0.5178\n",
            "Epoch 23/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0268 - accuracy: 0.5214\n",
            "Epoch 24/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0316 - accuracy: 0.5163\n",
            "Epoch 25/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0324 - accuracy: 0.5176\n",
            "Epoch 26/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0291 - accuracy: 0.5185\n",
            "Epoch 27/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0336 - accuracy: 0.5184\n",
            "Epoch 28/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0253 - accuracy: 0.5220\n",
            "Epoch 29/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0355 - accuracy: 0.5155\n",
            "Epoch 30/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0316 - accuracy: 0.5143\n",
            "Epoch 31/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0252 - accuracy: 0.5248\n",
            "Epoch 32/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0349 - accuracy: 0.5151\n",
            "Epoch 33/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0325 - accuracy: 0.5176\n",
            "Epoch 34/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0304 - accuracy: 0.5188\n",
            "Epoch 35/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0370 - accuracy: 0.5160\n",
            "Epoch 36/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0386 - accuracy: 0.5173\n",
            "Epoch 37/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0282 - accuracy: 0.5208\n",
            "Epoch 38/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0343 - accuracy: 0.5141\n",
            "Epoch 39/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0360 - accuracy: 0.5181\n",
            "Epoch 40/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0248 - accuracy: 0.5223\n",
            "Epoch 41/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0385 - accuracy: 0.5127\n",
            "Epoch 42/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0346 - accuracy: 0.5208\n",
            "Epoch 43/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0317 - accuracy: 0.5231\n",
            "Epoch 44/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0356 - accuracy: 0.5144\n",
            "Epoch 45/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0296 - accuracy: 0.5202\n",
            "Epoch 46/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0313 - accuracy: 0.5195\n",
            "Epoch 47/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0356 - accuracy: 0.5208\n",
            "Epoch 48/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0373 - accuracy: 0.5122\n",
            "Epoch 49/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0370 - accuracy: 0.5170\n",
            "Epoch 50/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0375 - accuracy: 0.5173\n",
            "Epoch 51/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0304 - accuracy: 0.5171\n",
            "Epoch 52/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0361 - accuracy: 0.5143\n",
            "Epoch 53/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0399 - accuracy: 0.5135\n",
            "Epoch 54/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0397 - accuracy: 0.5162\n",
            "Epoch 55/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0441 - accuracy: 0.5087\n",
            "Epoch 56/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0305 - accuracy: 0.5205\n",
            "Epoch 57/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0325 - accuracy: 0.5206\n",
            "Epoch 58/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0376 - accuracy: 0.5132\n",
            "Epoch 59/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0312 - accuracy: 0.5137\n",
            "Epoch 60/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0389 - accuracy: 0.5126\n",
            "Epoch 61/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0300 - accuracy: 0.5223\n",
            "Epoch 62/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0364 - accuracy: 0.5198\n",
            "Epoch 63/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0281 - accuracy: 0.5244\n",
            "Epoch 64/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0416 - accuracy: 0.5201\n",
            "Epoch 65/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0386 - accuracy: 0.5146\n",
            "Epoch 66/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0408 - accuracy: 0.5170\n",
            "Epoch 67/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0305 - accuracy: 0.5207\n",
            "Epoch 68/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0344 - accuracy: 0.5189\n",
            "Epoch 69/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0388 - accuracy: 0.5184\n",
            "Epoch 70/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0409 - accuracy: 0.5123\n",
            "Epoch 71/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0359 - accuracy: 0.5176\n",
            "Epoch 72/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0346 - accuracy: 0.5231\n",
            "Epoch 73/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0434 - accuracy: 0.5116\n",
            "Epoch 74/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0388 - accuracy: 0.5181\n",
            "Epoch 75/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0409 - accuracy: 0.5124\n",
            "Epoch 76/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0421 - accuracy: 0.5108\n",
            "Epoch 77/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0379 - accuracy: 0.5191\n",
            "Epoch 78/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0434 - accuracy: 0.5177\n",
            "Epoch 79/80\n",
            "16950/16950 [==============================] - 37s 2ms/step - loss: 1.0382 - accuracy: 0.5184\n",
            "Epoch 80/80\n",
            "16950/16950 [==============================] - 36s 2ms/step - loss: 1.0420 - accuracy: 0.5175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PVZjt0fnNjk",
        "outputId": "18c87ed4-4faa-44ae-fa37-bfb2b1079270"
      },
      "source": [
        "y_pred_opt_new = clf_new.predict(X_test_scaled, batch_size=opt_batch_size, verbose=1)\n",
        "y_pred_opt_new_bool = np.argmax(y_pred_opt_new, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_opt_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16641/16641 [==============================] - 15s 883us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.51      0.64    430538\n",
            "         1.0       0.23      0.35      0.28     90587\n",
            "         2.0       0.03      0.40      0.06     11381\n",
            "\n",
            "    accuracy                           0.48    532506\n",
            "   macro avg       0.38      0.42      0.33    532506\n",
            "weighted avg       0.74      0.48      0.56    532506\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0zvbDlsPZBe",
        "outputId": "6645be97-b45f-4fa2-fffd-efbd825187af"
      },
      "source": [
        "accuracy_new = accuracy_score(y_test, y_pred_opt_new_bool)\n",
        "print(\"Accuracy using train sample: {:.4}%\".format(accuracy_new * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using train sample: 49.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwv-NvkLP8JV",
        "outputId": "6f5fd5f8-6c12-4d44-869e-7f80b6d33ea8"
      },
      "source": [
        "!pip install deployml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deployml\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/93/c7af76ed847625195a4fcdd46618244d73defb4e7456831e7e8e25a4984e/deployml-0.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (from deployml) (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deployml) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deployml) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from deployml) (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from deployml) (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn->deployml) (0.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deployml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deployml) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deployml) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deployml) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deployml) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->deployml) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn->deployml) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deployml) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deployml) (1.0.1)\n",
            "Installing collected packages: deployml\n",
            "Successfully installed deployml-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN0e6-m1Plc9",
        "outputId": "ec10be43-e12c-47de-f4de-053da1a15f9e"
      },
      "source": [
        "# Save model\n",
        "filename = r'/content/drive/My Drive/Senior Project/mlp_clf_optuna_model.h5'\n",
        "# joblib.dump(clf_new, open(filename, 'wb'))\n",
        "# clf_new.deploy_model(description='Keras NN',\n",
        "#                 file_name=filename)\n",
        "# save model and architecture to single file\n",
        "clf_new.save(filename)\n",
        "if os.path.exists(filename):\n",
        "    print(\"Model Saved Successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjPk2sqiZybJ",
        "outputId": "171a6a7c-7433-4ce6-cec7-a0eb4bd238c3"
      },
      "source": [
        "# Testing Accuracy\n",
        "from sklearn.metrics import plot_confusion_matrix, classification_report, accuracy_score\n",
        "# plot_confusion_matrix(clf_new, X_scaled, y_pred_opt_new_bool, values_format='d')\n",
        "\n",
        "# y_pred = clf_new.predict(X_test_scaled, batch_size=opt_batch_size, verbose=1)\n",
        "# y_pred_bool = np.argmax(y_pred_opt_new, axis=1)\n",
        "# accuracy = accuracy_score(y_test, y_pred_opt_new_bool)\n",
        "# print(\"Accuracy: {:.4}%\".format(accuracy * 100))\n",
        "\n",
        "accuracy_new = accuracy_score(y_test, y_pred_opt_new_bool)\n",
        "print(\"Accuracy using train sample: {:.4}%\".format(accuracy_new * 100))\n",
        "\n",
        "print(classification_report(y_test, y_pred_opt_new_bool))\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "kappa = cohen_kappa_score(y_test, y_pred_opt_new_bool)\n",
        "print(\"Kappa Score: \" + str(kappa))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef \n",
        "\n",
        "print(\"MMC: \" + str(matthews_corrcoef(y_test, y_pred_opt_new_bool)))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"f1-score: \" + str(f1_score(y_test, y_pred_opt_new_bool, average='micro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using train sample: 49.4%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.55      0.67    430538\n",
            "         1.0       0.26      0.22      0.23     90587\n",
            "         2.0       0.03      0.51      0.06     11381\n",
            "\n",
            "    accuracy                           0.49    532506\n",
            "   macro avg       0.38      0.42      0.32    532506\n",
            "weighted avg       0.74      0.49      0.58    532506\n",
            "\n",
            "Kappa Score: 0.0767668274328368\n",
            "MMC: 0.09680132448345209\n",
            "f1-score: 0.49400194551798476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvU8_cumaCuY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}